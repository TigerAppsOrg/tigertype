name: Scrape & Import Snippets

on:
  workflow_dispatch:
    inputs:
      import_to_db:
        description: "Import processed snippets into DB after scrape+process"
        required: false
        type: boolean
        default: false
      term:
        description: "Registrar term code (4 digits, e.g. 1252)"
        required: true
        type: string
      subject:
        description: "3-letter subject (e.g. COS). Leave blank for all"
        required: false
        type: string
        default: ""
      course:
        description: "Optional course selector: 10-digit combined <term><course> (e.g. 1262002051) OR 5–6 digit course id (pads to 6 when term is provided)"
        required: false
        type: string
        default: ""
      phpsessid:
        description: "PHPSESSID cookie value from registrar (https://registrarapps.princeton.edu/course-evaluation/search)"
        required: true
        type: string
      oit_api_key:
        description: "OIT Student-App bearer token (optional if set as secret)"
        required: false
        type: string
        default: ""
      environment:
        description: "Target environment for secrets"
        required: false
        default: tigertype
        type: choice
        options:
          - tigertype
          - staging

run-name: "Import ${{ inputs.subject || 'ALL' }} snippets for ${{ inputs.term }}"

jobs:
  # Job 1: Scrape course evaluations from Princeton registrar
  scrape:
    name: "📥 Scrape Evaluations"
    runs-on: ubuntu-latest
    environment: ${{ inputs.environment }}
    outputs:
      courses_count: ${{ steps.scrape.outputs.courses_count }}
      snippets_count: ${{ steps.scrape.outputs.snippets_count }}
      semester: ${{ steps.parse_term.outputs.semester }}
      subject_display: ${{ steps.parse_term.outputs.subject_display }}
    
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20.11.1'

      - name: Install Node dependencies
        run: |
          if [ -f package-lock.json ]; then
            npm ci
          else
            echo "package-lock.json not found; using npm install"
            npm install
          fi

      - name: Mask sensitive inputs
        run: |
          if [ -n "${{ github.event.inputs.phpsessid }}" ]; then echo "::add-mask::${{ github.event.inputs.phpsessid }}"; fi
          if [ -n "${{ github.event.inputs.oit_api_key }}" ]; then echo "::add-mask::${{ github.event.inputs.oit_api_key }}"; fi
          if [ -n "${{ secrets.PRINCETON_API_KEY }}" ]; then echo "::add-mask::${{ secrets.PRINCETON_API_KEY }}"; fi

      - name: Parse term code to semester
        id: parse_term
        run: |
          TERM="${{ github.event.inputs.term }}"
          # extract year and semester from term code (e.g., 1252)
          # format: 12YS where Y is year offset from 2020, S is semester (2=Fall, 4=Spring)
          YEAR_DIGIT="${TERM:2:1}"
          SEM_DIGIT="${TERM:3:1}"
          
          # calculate year
          YEAR=$((2020 + YEAR_DIGIT))
          
          # determine semester
          case "$SEM_DIGIT" in
            2) SEMESTER="Fall"; DISPLAY_YEAR=$YEAR ;;
            4) SEMESTER="Spring"; DISPLAY_YEAR=$((YEAR + 1)) ;;
            *) SEMESTER="Unknown"; DISPLAY_YEAR=$YEAR ;;
          esac
          
          SEMESTER_DISPLAY="${SEMESTER} ${DISPLAY_YEAR}"
          echo "semester=$SEMESTER_DISPLAY" >> "$GITHUB_OUTPUT"
          echo "year=$DISPLAY_YEAR" >> "$GITHUB_OUTPUT"
          echo "semester_name=$SEMESTER" >> "$GITHUB_OUTPUT"
          
          # set subject display
          SUBJECT="${{ github.event.inputs.subject }}"
          if [ -z "$SUBJECT" ]; then
            echo "subject_display=ALL subjects" >> "$GITHUB_OUTPUT"
          else
            echo "subject_display=$SUBJECT" >> "$GITHUB_OUTPUT"
          fi

      - name: Prepare scraper environment
        run: |
          KEY_INPUT="${{ github.event.inputs.oit_api_key }}"
          KEY_SECRET="${{ secrets.PRINCETON_API_KEY }}"
          KEY="$KEY_INPUT"
          if [ -z "$KEY" ]; then KEY="$KEY_SECRET"; fi
          if [ -z "$KEY" ]; then
            echo "::error::Missing OIT Student-App token. Provide 'oit_api_key' input or set PRINCETON_API_KEY as a repo/environment secret."
            exit 1
          fi
          echo "PRINCETON_API_KEY=$KEY" >> "$GITHUB_ENV"
          echo "PHPSESSID=${{ github.event.inputs.phpsessid }}" >> "$GITHUB_ENV"
          echo "TERM=${{ github.event.inputs.term }}" >> "$GITHUB_ENV"
          echo "SUBJECT=${{ github.event.inputs.subject }}" >> "$GITHUB_ENV"
          echo "COURSE=${{ github.event.inputs.course }}" >> "$GITHUB_ENV"

      - name: Scrape evaluations
        id: scrape
        run: |
          node server/scraping/scrape_evals.js
          ls -lh server/scraping/data/raw_evaluations.json
          
          # count courses and snippets scraped
          if [ -f server/scraping/data/raw_evaluations.json ]; then
            COURSES_COUNT=$(jq 'length' server/scraping/data/raw_evaluations.json)
            SNIPPETS_COUNT=$(jq '[.[] | .questions // []] | add | length' server/scraping/data/raw_evaluations.json)
            echo "courses_count=$COURSES_COUNT" >> "$GITHUB_OUTPUT"
            echo "snippets_count=$SNIPPETS_COUNT" >> "$GITHUB_OUTPUT"
            
            echo "# 📥 Scraping Results" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "**Semester:** ${{ steps.parse_term.outputs.semester }}" >> $GITHUB_STEP_SUMMARY
            echo "**Subject(s):** ${{ steps.parse_term.outputs.subject_display }}" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "| Metric | Count |" >> $GITHUB_STEP_SUMMARY
            echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
            echo "| Courses found | $COURSES_COUNT |" >> $GITHUB_STEP_SUMMARY
            echo "| Raw snippets extracted | $SNIPPETS_COUNT |" >> $GITHUB_STEP_SUMMARY
          fi

      - name: Upload raw evaluations artifact
        uses: actions/upload-artifact@v4
        with:
          name: raw_evaluations
          path: server/scraping/data/raw_evaluations.json
          retention-days: 30

  # Job 2: Process raw evaluations with AI
  process:
    name: "🤖 AI Processing"
    runs-on: ubuntu-latest
    needs: scrape
    environment: ${{ inputs.environment }}
    outputs:
      processed_count: ${{ steps.process.outputs.processed_count }}
    
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Download raw evaluations artifact
        uses: actions/download-artifact@v4
        with:
          name: raw_evaluations
          path: server/scraping/data/

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install openai python-dotenv psycopg2-binary

      - name: Process evaluations with AI
        id: process
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          python server/scraping/process_evals.py
          ls -lh server/scraping/data/processed_snippets.json
          
          # count processed snippets
          if [ -f server/scraping/data/processed_snippets.json ]; then
            PROCESSED_COUNT=$(jq 'length' server/scraping/data/processed_snippets.json)
            echo "processed_count=$PROCESSED_COUNT" >> "$GITHUB_OUTPUT"
            
            # calculate selection rate
            SELECTION_RATE=$(echo "scale=1; $PROCESSED_COUNT * 100 / ${{ needs.scrape.outputs.snippets_count }}" | bc)
            
            echo "# 🤖 AI Processing Results" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "| Metric | Count |" >> $GITHUB_STEP_SUMMARY
            echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
            echo "| Raw snippets (input) | ${{ needs.scrape.outputs.snippets_count }} |" >> $GITHUB_STEP_SUMMARY
            echo "| Snippets selected by AI | $PROCESSED_COUNT |" >> $GITHUB_STEP_SUMMARY
            echo "| Selection rate | ${SELECTION_RATE}% |" >> $GITHUB_STEP_SUMMARY
          fi

      - name: Upload processed snippets artifact
        uses: actions/upload-artifact@v4
        with:
          name: processed_snippets
          path: server/scraping/data/processed_snippets.json
          retention-days: 30

  # Job 3: Import processed snippets into database
  import:
    name: "💾 Database Import"
    runs-on: ubuntu-latest
    needs: [scrape, process]
    if: ${{ github.event.inputs.import_to_db == 'true' }}
    environment: ${{ inputs.environment }}
    outputs:
      imported_count: ${{ steps.import.outputs.imported_count }}
    
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Download processed snippets artifact
        uses: actions/download-artifact@v4
        with:
          name: processed_snippets
          path: server/scraping/data/

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install python-dotenv psycopg2-binary

      - name: Import snippets to database
        id: import
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
        run: |
          python server/scraping/import_snippets.py --production | tee import_output.log
          
          # try to extract import count from output
          IMPORTED=$(grep -oP 'imported \K\d+' import_output.log | tail -1 || echo "unknown")
          echo "imported_count=$IMPORTED" >> "$GITHUB_OUTPUT"
          
          echo "# 💾 Database Import" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "✅ **Import completed successfully**" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          if [ "$IMPORTED" != "unknown" ]; then
            echo "| Metric | Count |" >> $GITHUB_STEP_SUMMARY
            echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
            echo "| Snippets imported | $IMPORTED |" >> $GITHUB_STEP_SUMMARY
          fi

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20.11.1'

      - name: Install Node dependencies
        run: |
          if [ -f package-lock.json ]; then
            npm ci
          else
            npm install
          fi

      - name: Post-import newline fix
        env:
          NODE_ENV: production
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
        run: |
          node server/scripts/fix_snippet_trailing_newlines.js --apply

      - name: Verify no duplicates
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
        run: |
          node server/scripts/verify_snippet_duplicates.js

  # Job 4: Generate comprehensive summary
  summary:
    name: "📊 Summary"
    runs-on: ubuntu-latest
    needs: [scrape, process, import]
    if: always()
    
    steps:
      - name: Generate comprehensive summary
        run: |
          echo "# 📊 Snippet Import Workflow Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          echo "## ⚙️ Configuration" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Setting | Value |" >> $GITHUB_STEP_SUMMARY
          echo "|---------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| Semester | ${{ needs.scrape.outputs.semester }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Term Code | \`${{ github.event.inputs.term }}\` |" >> $GITHUB_STEP_SUMMARY
          echo "| Subject(s) | ${{ needs.scrape.outputs.subject_display }} |" >> $GITHUB_STEP_SUMMARY
          if [ -n "${{ github.event.inputs.course }}" ]; then
            echo "| Course Filter | \`${{ github.event.inputs.course }}\` |" >> $GITHUB_STEP_SUMMARY
          fi
          echo "| Import to DB | ${{ github.event.inputs.import_to_db }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          echo "## 📈 Results Pipeline" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Stage | Status | Count |" >> $GITHUB_STEP_SUMMARY
          echo "|-------|--------|-------|" >> $GITHUB_STEP_SUMMARY
          
          # scrape job
          if [ "${{ needs.scrape.result }}" == "success" ]; then
            echo "| 📥 Scraping | ✅ Success | ${{ needs.scrape.outputs.courses_count }} courses, ${{ needs.scrape.outputs.snippets_count }} snippets |" >> $GITHUB_STEP_SUMMARY
          else
            echo "| 📥 Scraping | ❌ Failed | - |" >> $GITHUB_STEP_SUMMARY
          fi
          
          # process job
          if [ "${{ needs.process.result }}" == "success" ]; then
            echo "| 🤖 AI Processing | ✅ Success | ${{ needs.process.outputs.processed_count }} snippets selected |" >> $GITHUB_STEP_SUMMARY
          elif [ "${{ needs.process.result }}" == "skipped" ]; then
            echo "| 🤖 AI Processing | ⏭️ Skipped | - |" >> $GITHUB_STEP_SUMMARY
          else
            echo "| 🤖 AI Processing | ❌ Failed | - |" >> $GITHUB_STEP_SUMMARY
          fi
          
          # import job
          if [ "${{ needs.import.result }}" == "success" ]; then
            IMPORTED="${{ needs.import.outputs.imported_count }}"
            if [ "$IMPORTED" != "unknown" ] && [ -n "$IMPORTED" ]; then
              echo "| 💾 Database Import | ✅ Success | $IMPORTED snippets imported |" >> $GITHUB_STEP_SUMMARY
            else
              echo "| 💾 Database Import | ✅ Success | Completed |" >> $GITHUB_STEP_SUMMARY
            fi
          elif [ "${{ needs.import.result }}" == "skipped" ]; then
            echo "| 💾 Database Import | ⏭️ Skipped | import_to_db = false |" >> $GITHUB_STEP_SUMMARY
          else
            echo "| 💾 Database Import | ❌ Failed | - |" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## 📦 Artifacts" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- \`raw_evaluations.json\` - Raw scraped course evaluations" >> $GITHUB_STEP_SUMMARY
          echo "- \`processed_snippets.json\` - AI-filtered and processed snippets" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # overall status
          echo "## 🎯 Overall Status" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          if [ "${{ needs.scrape.result }}" == "success" ] && [ "${{ needs.process.result }}" == "success" ]; then
            if [ "${{ github.event.inputs.import_to_db }}" == "true" ]; then
              if [ "${{ needs.import.result }}" == "success" ]; then
                echo "✅ **All stages completed successfully!**" >> $GITHUB_STEP_SUMMARY
              else
                echo "⚠️ **Scraping and processing succeeded, but import failed.**" >> $GITHUB_STEP_SUMMARY
              fi
            else
              echo "✅ **Scraping and processing completed successfully. Database import was skipped.**" >> $GITHUB_STEP_SUMMARY
            fi
          else
            echo "❌ **Workflow encountered errors. Check individual job logs for details.**" >> $GITHUB_STEP_SUMMARY
          fi